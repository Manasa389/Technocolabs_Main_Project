{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Lc_Data Modeling(LR).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz_iq99SabDq",
        "outputId": "2ff882ad-aec5-47ac-a5ee-5be9d45f21b6"
      },
      "source": [
        "#Let's mount the google drive with colab:\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtVxJsqGawNx",
        "outputId": "1c361c0a-c200-4c3f-b95e-6c5288a5ba1e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afgKw1O6abGh"
      },
      "source": [
        "#importing python libraries for analysis:\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split,cross_val_predict\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "tUgOk8FwbIC5",
        "outputId": "6e1f2ef8-0f22-4ef5-a8a2-6789a2324a85"
      },
      "source": [
        "df_Lending_Club = pd.read_csv(\"/content/drive/MyDrive/Kaggle/Lending_Club_Loan_approval_Optimization.csv\")\n",
        "df_Lending_Club.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "df_Lending_Club.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Amount Requested</th>\n",
              "      <th>Risk_Score</th>\n",
              "      <th>Debt-To-Income Ratio</th>\n",
              "      <th>Employment Length</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3600.0</td>\n",
              "      <td>677.0</td>\n",
              "      <td>5.91</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24700.0</td>\n",
              "      <td>717.0</td>\n",
              "      <td>16.06</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20000.0</td>\n",
              "      <td>697.0</td>\n",
              "      <td>10.78</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10400.0</td>\n",
              "      <td>697.0</td>\n",
              "      <td>25.37</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11950.0</td>\n",
              "      <td>692.0</td>\n",
              "      <td>10.20</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Amount Requested  Risk_Score  ...  Employment Length  Target\n",
              "0            3600.0       677.0  ...                 10       1\n",
              "1           24700.0       717.0  ...                 10       1\n",
              "2           20000.0       697.0  ...                 10       1\n",
              "3           10400.0       697.0  ...                  3       1\n",
              "4           11950.0       692.0  ...                  4       1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkzkb3VOSVz3"
      },
      "source": [
        "#**Let's split the data for training and testing:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKwFmJEMLCGt"
      },
      "source": [
        "# spliting training and testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_Lending_Club.iloc[:,:-1].values\n",
        "y = df_Lending_Club.iloc[:,-1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKELEQhCT5gz",
        "outputId": "09af393f-f1e7-4b45-914e-4f595967a884"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1658244, 4)\n",
            "(1658244,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbxpfGkM0KNR"
      },
      "source": [
        "#**Let's Scale Down :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1O70BqA0Da_"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler, RobustScaler\n",
        "\n",
        "Normalisation = MinMaxScaler()      # Scale down from 0 to 1\n",
        "Standardisation = StandardScaler()  # Scale down mean=0, std=1. (range = -3 to +3)\n",
        "Robust = RobustScaler()             # Median and IQR values stored and then transformed."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYcLUnOQ0Ddq"
      },
      "source": [
        "#Fit the data\n",
        "\n",
        "norm = Normalisation.fit(X_train)\n",
        "stand = Standardisation.fit(X_train)\n",
        "robust = Robust.fit(X_train)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVFL6y6P-UbK"
      },
      "source": [
        "#Transform the Training dataset:\n",
        "\n",
        "X_train_norm = norm.transform(X_train)    \n",
        "X_train_stand = stand.transform(X_train)\n",
        "X_train_robust = robust.transform(X_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JewY9v4-UeK"
      },
      "source": [
        "#Transform the Testing dataset:\n",
        "\n",
        "X_test_norm = norm.transform(X_test)\n",
        "X_test_stand = stand.transform(X_test)\n",
        "X_test_robust = robust.transform(X_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9gvXXPX_oj2"
      },
      "source": [
        "#**We can achieve above step by using like this too,**\n",
        "\n",
        "* **X_train_norm = MinMaxScaler().fit_transform(X_train)**  #Fit for train\n",
        "* **X_test_norm = norm.transform(X_test)**  \n",
        "#transform alone sufficient(already train got fit)\n",
        "\n",
        "or\n",
        "\n",
        "* **norm = MinMaxScaler().fit(X_train)**\n",
        "* **X_train_norm = norm.transform(X_train)**\n",
        "* **X_test_norm = norm.transform(X_test)**\n",
        "\n",
        "or \n",
        " \n",
        "* **norm = MinMaxScaler().fit_transform(X_train)**\n",
        "* **X_test_norm = norm.transform(X_test)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6x5O0rNADdd"
      },
      "source": [
        "X_train = [X_train, X_train_norm, X_train_stand, X_train_robust]\n",
        "y_train = y_train\n",
        "X_test = [X_test, X_test_norm, X_test_stand, X_test_robust]\n",
        "y_test = y_test"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZp4hhoOz2pA"
      },
      "source": [
        "#**(1) Let's apply LogisticRegression Algorithm:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f721h2UwuTzg"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "Model_lr = LogisticRegression()\n",
        "Model_Norm_lr = LogisticRegression()\n",
        "Model_Stand_lr = LogisticRegression()\n",
        "Model_Robust_lr = LogisticRegression()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLysdUeotD1l"
      },
      "source": [
        "Models = [\"LogisticRegression Without Scaling :\", \"LogisticRegression with Normalisation :\", \n",
        "          \"LogisticRegression with Standardisation :\", \"LogisticRegression with Robust Scaling :\"]\n",
        "\n",
        "LR = [Model_lr, Model_Norm_lr, Model_Stand_lr, Model_Robust_lr]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIz5iPGuRyWp",
        "outputId": "55191459-e24f-45a0-8f10-a2ff77c78d27"
      },
      "source": [
        "for i in range (4):\n",
        "  LR[i].fit(X_train[i], y_train)       #Fit the training data in Logistic Regression\n",
        "  y_pred = LR[i].predict(X_test[i])    #Predict the score\n",
        "  y_pred\n",
        "  print()\n",
        "  print(Models[i])                     #Print the Model description\n",
        "  print(\"Accuracy score of training data {} %:\".format(LR[i].score(X_train[i], y_train)*100))\n",
        "  print(\"Accuracy score of testing data {} %\".format(LR[i].score(X_test[i], y_test)*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "LogisticRegression Without Scaling :\n",
            "Accuracy score of training data 78.80281792064376 %:\n",
            "Accuracy score of testing data 78.94766042232526 %\n",
            "\n",
            "LogisticRegression with Normalisation :\n",
            "Accuracy score of training data 81.89217027168499 %:\n",
            "Accuracy score of testing data 81.95879024126668 %\n",
            "\n",
            "LogisticRegression with Standardisation :\n",
            "Accuracy score of training data 85.40588719151103 %:\n",
            "Accuracy score of testing data 85.44319064458392 %\n",
            "\n",
            "LogisticRegression with Robust Scaling :\n",
            "Accuracy score of training data 85.73267866490094 %:\n",
            "Accuracy score of testing data 85.78162011954787 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTBDlTYUYpo_"
      },
      "source": [
        "Looks Standardisation and Robust Scaling both provides good accuracy comparing others. So let's proceed hyperparameter tuning with Standardisation and Robust Scaling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_731YE3BkAP",
        "outputId": "b0897fda-def4-49a6-a7b3-d4e0faf16888"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "models = [\"Confusion Matrix with Standardisation Scaling :\",\"Confusion Matrix with Robust Scaling :\"]\n",
        "\n",
        "for i in range (2):\n",
        "  y_pred_test = LR[i].predict(X_test[i])    #Predict the score\n",
        "  cm = confusion_matrix(y_test, y_pred_test)\n",
        "  print(models[i])\n",
        "  print(cm)\n",
        "  print()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix with Standardisation Scaling :\n",
            "[[169649  37850]\n",
            " [ 49425 157638]]\n",
            "\n",
            "Confusion Matrix with Robust Scaling :\n",
            "[[159821  47678]\n",
            " [ 27114 179949]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIzdn-t7aK_V"
      },
      "source": [
        "#**(i) Standardisation :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvFtP0fGkPC2",
        "outputId": "1bf33756-9e0e-433b-e313-baa23940ea58"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "model = LogisticRegression()\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l1', 'l2']\n",
        "c_values = [0.1, 1, 10, 15, 20, 100, 105, 110]\n",
        "\n",
        "# define grid search\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X_train_stand, y_train)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.857322 using {'C': 20, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.852119 (0.001028) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.835195 (0.001021) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.835195 (0.001021) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.835174 (0.001028) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.852199 (0.000938) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.853582 (0.000940) with: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.853582 (0.000940) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.853550 (0.000947) with: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.852210 (0.001061) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857198 (0.000868) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857199 (0.000869) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857196 (0.000870) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 15, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 15, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.852209 (0.000990) with: {'C': 15, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857305 (0.000865) with: {'C': 15, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857305 (0.000865) with: {'C': 15, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857302 (0.000862) with: {'C': 15, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 20, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 20, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.852250 (0.001305) with: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857322 (0.000874) with: {'C': 20, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857322 (0.000874) with: {'C': 20, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857321 (0.000872) with: {'C': 20, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 100, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 100, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.852234 (0.000989) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857305 (0.000862) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857305 (0.000863) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857302 (0.000860) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 105, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 105, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.852130 (0.001179) with: {'C': 105, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857305 (0.000861) with: {'C': 105, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857305 (0.000861) with: {'C': 105, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857303 (0.000862) with: {'C': 105, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 110, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 110, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.852243 (0.001002) with: {'C': 110, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857307 (0.000860) with: {'C': 110, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857306 (0.000861) with: {'C': 110, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857306 (0.000860) with: {'C': 110, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwDZbYU9n8TZ"
      },
      "source": [
        "#**Let's Retrain the Model by using the best parameters :**\n",
        "\n",
        "Stratified CV:  Best: 0.857322 using {'C': 20, 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqmXOexeCnVd",
        "outputId": "b4317b91-dd8f-482b-9e9d-cd0fe041d349"
      },
      "source": [
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "logistic_R = LogisticRegression( C= 20, penalty= 'l2', solver='lbfgs', n_jobs=-1)\n",
        "logistic_R.fit(X_train_stand, y_train)\n",
        "print(\"Accuracy score of training data {} %:\".format(logistic_R.score(X_train_stand, y_train)*100))\n",
        "print(\"Accuracy score of testing data {} %\".format(logistic_R.score(X_test_stand, y_test)*100))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score of training data 85.7344275028283 %:\n",
            "Accuracy score of testing data 85.78958032815358 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlB8Jy2gHNfG"
      },
      "source": [
        "#**(ii) Randomization:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLJDOUkziy--",
        "outputId": "93178a9e-5f6b-4196-b253-0bd9cd6986a2"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "model = LogisticRegression()\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l1', 'l2']\n",
        "c_values = [0.01, 0.1, 1, 10, 15, 20, 100, 105]\n",
        "\n",
        "# define grid search\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X_train_robust, y_train)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.857356 using {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.846117 (0.002116) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857356 (0.000852) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857356 (0.000853) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857353 (0.000852) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.846090 (0.002122) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857322 (0.000857) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857322 (0.000857) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857329 (0.000859) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.846077 (0.002102) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857321 (0.000856) with: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857321 (0.000856) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857327 (0.000857) with: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.846039 (0.002073) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857320 (0.000856) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857320 (0.000856) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857327 (0.000857) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 15, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 15, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.846089 (0.002057) with: {'C': 15, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857320 (0.000855) with: {'C': 15, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857320 (0.000856) with: {'C': 15, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857327 (0.000857) with: {'C': 15, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 20, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 20, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.846093 (0.002140) with: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857320 (0.000855) with: {'C': 20, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857320 (0.000856) with: {'C': 20, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857327 (0.000857) with: {'C': 20, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 100, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 100, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.846044 (0.002115) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857320 (0.000855) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857320 (0.000856) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857327 (0.000857) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 105, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 105, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.846134 (0.002057) with: {'C': 105, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.857320 (0.000855) with: {'C': 105, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.857320 (0.000856) with: {'C': 105, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.857327 (0.000857) with: {'C': 105, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaWlX9WxpTgS"
      },
      "source": [
        "#**Let's Retrain the Model by using the best parameters :**\n",
        "\n",
        "stratified : Best: 0.857356 using {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_hgXAl8G2_H",
        "outputId": "96d537de-9ac4-4c01-b20a-4d1bf7d17ca1"
      },
      "source": [
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "logistic_R = LogisticRegression( C= 0.01, penalty= 'l2', solver='lbfgs', n_jobs=-1)\n",
        "logistic_R.fit(X_train_robust, y_train)\n",
        "print(\"Accuracy score of training data {} %:\".format(logistic_R.score(X_train_robust, y_train)*100))\n",
        "print(\"Accuracy score of testing data {} %\".format(logistic_R.score(X_test_robust, y_test)*100))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score of training data 85.7356335979506 %:\n",
            "Accuracy score of testing data 85.785720833072 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}